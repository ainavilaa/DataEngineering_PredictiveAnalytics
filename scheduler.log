/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2025-12-29T20:42:22.186+0100] {_client.py:1026} INFO - HTTP Request: GET https://apacheairflow.gateway.scarf.sh/scheduler?version=2.10.3&python_version=3.12&platform=Linux&arch=x86_64&database=sqlite&db_version=3.45&executor=SequentialExecutor "HTTP/1.1 200 OK"
[2025-12-29T20:42:22.920+0100] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2025-12-29 20:42:22 +0100] [184689] [INFO] Starting gunicorn 21.2.0
[2025-12-29 20:42:22 +0100] [184689] [ERROR] Connection in use: ('::', 8793)
[2025-12-29 20:42:22 +0100] [184689] [ERROR] Retrying in 1 second.
[2025-12-29T20:42:23.005+0100] {scheduler_job_runner.py:938} INFO - Starting the scheduler
[2025-12-29T20:42:23.007+0100] {scheduler_job_runner.py:945} INFO - Processing each file at most -1 times
[2025-12-29T20:42:23.020+0100] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 184690
[2025-12-29T20:42:23.024+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T20:42:23.029+0100] {settings.py:63} INFO - Configured default timezone UTC
[2025-12-29T20:42:23.076+0100] {scheduler_job_runner.py:1915} INFO - Reset the following 1 orphaned TaskInstances:
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices scheduled__2025-12-28T00:00:00+00:00 [running]>
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:42:23.082+0100] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
Dag run  in running state
Dag information Queued at: 2025-12-29 19:32:36.724642+00:00 hash info: d14172f209e877fbcd41cb8a5b17e933
[2025-12-29T20:42:23.455+0100] {scheduler_job_runner.py:423} INFO - 5 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:30:52+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices scheduled__2025-12-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_culture scheduled__2025-12-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:30:52+00:00 [scheduled]>
[2025-12-29T20:42:23.456+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:42:23.456+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 1/16 running and queued tasks
[2025-12-29T20:42:23.456+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 2/16 running and queued tasks
[2025-12-29T20:42:23.457+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 3/16 running and queued tasks
[2025-12-29T20:42:23.457+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 4/16 running and queued tasks
[2025-12-29T20:42:23.458+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:30:52+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices scheduled__2025-12-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_culture scheduled__2025-12-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:30:52+00:00 [scheduled]>
[2025-12-29T20:42:23.462+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:32:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:30:52+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.format_prices scheduled__2025-12-28T00:00:00+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.format_culture scheduled__2025-12-28T00:00:00+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:30:52+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:42:23.463+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='mark_execution_start', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 11 and queue default
[2025-12-29T20:42:23.464+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'mark_execution_start', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:42:23.465+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_culture', run_id='manual__2025-12-29T19:30:52+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-12-29T20:42:23.465+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_culture', 'manual__2025-12-29T19:30:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:42:23.465+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='scheduled__2025-12-28T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T20:42:23.466+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'scheduled__2025-12-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:42:23.466+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_culture', run_id='scheduled__2025-12-28T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T20:42:23.466+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_culture', 'scheduled__2025-12-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:42:23.467+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='manual__2025-12-29T19:30:52+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T20:42:23.467+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'manual__2025-12-29T19:30:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:42:23.482+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'mark_execution_start', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29 20:42:23 +0100] [184689] [ERROR] Connection in use: ('::', 8793)
[2025-12-29 20:42:23 +0100] [184689] [ERROR] Retrying in 1 second.
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29 20:42:24 +0100] [184689] [ERROR] Connection in use: ('::', 8793)
[2025-12-29 20:42:24 +0100] [184689] [ERROR] Retrying in 1 second.
[2025-12-29 20:42:25 +0100] [184689] [ERROR] Connection in use: ('::', 8793)
[2025-12-29 20:42:25 +0100] [184689] [ERROR] Retrying in 1 second.
[2025-12-29T20:42:26.781+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29 20:42:26 +0100] [184689] [ERROR] Connection in use: ('::', 8793)
[2025-12-29 20:42:26 +0100] [184689] [ERROR] Retrying in 1 second.
[2025-12-29T20:42:27.414+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:42:27.675+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:42:27.677+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:42:27.718+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:42:27.788+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:42:27.790+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:42:27.830+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:32:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29 20:42:27 +0100] [184689] [ERROR] Can't connect to ('::', 8793)
[2025-12-29T20:42:28.719+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_culture', 'manual__2025-12-29T19:30:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:42:31.267+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:42:31.938+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:42:32.176+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:42:32.179+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:42:32.234+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:42:32.330+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:42:32.332+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:42:32.389+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:30:52+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:42:47.671+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'scheduled__2025-12-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:42:49.134+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:42:49.558+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:42:49.726+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:42:49.728+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:42:49.776+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:42:49.832+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:42:49.833+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:42:49.874+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_prices scheduled__2025-12-28T00:00:00+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:43:27.230+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_culture', 'scheduled__2025-12-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:43:29.621+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:43:30.156+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:43:30.374+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:43:30.377+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:43:30.419+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:43:30.498+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:43:30.499+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:43:30.548+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_culture scheduled__2025-12-28T00:00:00+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:43:54.964+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'manual__2025-12-29T19:30:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:43:59.113+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:43:59.750+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:43:59.944+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:43:59.946+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:43:59.989+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:00.073+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:44:00.074+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:00.132+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:30:52+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:44:10.768+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='mark_execution_start', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:44:10.769+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_culture', run_id='manual__2025-12-29T19:30:52+00:00', try_number=1, map_index=-1)
[2025-12-29T20:44:10.769+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='scheduled__2025-12-28T00:00:00+00:00', try_number=2, map_index=-1)
[2025-12-29T20:44:10.770+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_culture', run_id='scheduled__2025-12-28T00:00:00+00:00', try_number=1, map_index=-1)
[2025-12-29T20:44:10.770+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='manual__2025-12-29T19:30:52+00:00', try_number=1, map_index=-1)
[2025-12-29T20:44:10.781+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=collect_culture, run_id=manual__2025-12-29T19:30:52+00:00, map_index=-1, run_start_date=2025-12-29 19:42:32.476393+00:00, run_end_date=2025-12-29 19:42:47.322184+00:00, run_duration=14.845791, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=19, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-12-29 19:42:23.459679+00:00, queued_by_job_id=17, pid=184793
[2025-12-29T20:44:10.783+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_prices, run_id=manual__2025-12-29T19:30:52+00:00, map_index=-1, run_start_date=2025-12-29 19:44:00.200926+00:00, run_end_date=2025-12-29 19:44:10.173608+00:00, run_duration=9.972682, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=22, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 19:42:23.459679+00:00, queued_by_job_id=17, pid=186247
[2025-12-29T20:44:10.784+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=mark_execution_start, run_id=manual__2025-12-29T19:32:36+00:00, map_index=-1, run_start_date=2025-12-29 19:42:27.890545+00:00, run_end_date=2025-12-29 19:42:28.108639+00:00, run_duration=0.218094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=18, pool=default_pool, queue=default, priority_weight=11, operator=PythonOperator, queued_dttm=2025-12-29 19:42:23.459679+00:00, queued_by_job_id=17, pid=184758
[2025-12-29T20:44:10.784+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_culture, run_id=scheduled__2025-12-28T00:00:00+00:00, map_index=-1, run_start_date=2025-12-29 19:43:30.637414+00:00, run_end_date=2025-12-29 19:43:54.112727+00:00, run_duration=23.475313, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=21, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 19:42:23.459679+00:00, queued_by_job_id=17, pid=185756
[2025-12-29T20:44:10.785+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_prices, run_id=scheduled__2025-12-28T00:00:00+00:00, map_index=-1, run_start_date=2025-12-29 19:42:49.934274+00:00, run_end_date=2025-12-29 19:43:26.717320+00:00, run_duration=36.783046, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=20, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 19:42:23.459679+00:00, queued_by_job_id=17, pid=185041
[2025-12-29T20:44:10.797+0100] {manager.py:293} ERROR - DagFileProcessorManager (PID=184690) last sent a heartbeat 107.51 seconds ago! Restarting it
[2025-12-29T20:44:10.800+0100] {process_utils.py:132} INFO - Sending 15 to group 184690. PIDs of all processes in the group: [184690]
[2025-12-29T20:44:10.800+0100] {process_utils.py:87} INFO - Sending the signal 15 to group 184690
[2025-12-29T20:44:10.974+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=184690, status='terminated', exitcode=0, started='20:42:22') (184690) terminated with exit code 0
[2025-12-29T20:44:10.980+0100] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 186537
[2025-12-29T20:44:10.988+0100] {settings.py:63} INFO - Configured default timezone UTC
[2025-12-29T20:44:11.016+0100] {job.py:229} INFO - Heartbeat recovered after 108.73 seconds
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:44:11.027+0100] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
Dag run  in running state
Dag information Queued at: 2025-12-29 19:43:36.612088+00:00 hash info: d14172f209e877fbcd41cb8a5b17e933
[2025-12-29T20:44:11.281+0100] {scheduler_job_runner.py:423} INFO - 6 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:30:52+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone scheduled__2025-12-28T00:00:00+00:00 [scheduled]>
[2025-12-29T20:44:11.282+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:44:11.282+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 1/16 running and queued tasks
[2025-12-29T20:44:11.283+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 2/16 running and queued tasks
[2025-12-29T20:44:11.283+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 3/16 running and queued tasks
[2025-12-29T20:44:11.283+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 4/16 running and queued tasks
[2025-12-29T20:44:11.284+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 5/16 running and queued tasks
[2025-12-29T20:44:11.284+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:30:52+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone scheduled__2025-12-28T00:00:00+00:00 [scheduled]>
[2025-12-29T20:44:11.287+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:43:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:32:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:32:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:32:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:30:52+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone scheduled__2025-12-28T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:44:11.288+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='mark_execution_start', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 11 and queue default
[2025-12-29T20:44:11.289+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'mark_execution_start', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:44:11.289+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_culture_schedule', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-12-29T20:44:11.290+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_culture_schedule', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:44:11.290+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_accidents_schedule', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-12-29T20:44:11.291+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_accidents_schedule', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:44:11.291+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_prices', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-12-29T20:44:11.292+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_prices', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:44:11.292+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_culture', run_id='manual__2025-12-29T19:30:52+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T20:44:11.292+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_culture', 'manual__2025-12-29T19:30:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:44:11.293+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='scheduled__2025-12-28T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-12-29T20:44:11.293+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'scheduled__2025-12-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:44:11.305+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'mark_execution_start', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:44:14.405+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:44:14.885+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:44:15.061+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:15.063+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:15.104+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:15.162+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:44:15.163+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:15.200+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:43:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:44:16.169+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_culture_schedule', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:44:18.335+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:44:18.737+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:44:18.896+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:18.898+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:18.930+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:18.994+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:44:18.995+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:19.024+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:32:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:44:19.817+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_accidents_schedule', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:44:21.541+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:44:21.943+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:44:22.084+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:22.086+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:22.109+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:22.163+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:44:22.164+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:22.192+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:32:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:44:22.990+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_prices', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:44:24.906+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:44:25.527+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:44:25.737+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:25.740+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:25.801+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:25.892+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:44:25.894+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:25.937+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:32:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:44:42.849+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_culture', 'manual__2025-12-29T19:30:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:44:44.572+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:44:44.931+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:44:45.091+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:45.093+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:45.141+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:45.192+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:44:45.192+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:45.222+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:30:52+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:44:57.071+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'scheduled__2025-12-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:44:59.192+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:44:59.626+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:44:59.763+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:59.765+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:59.792+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:44:59.841+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:44:59.842+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:44:59.876+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone scheduled__2025-12-28T00:00:00+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:45:14.309+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='mark_execution_start', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:45:14.310+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_culture_schedule', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:45:14.310+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_accidents_schedule', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:45:14.310+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_prices', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:45:14.311+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_culture', run_id='manual__2025-12-29T19:30:52+00:00', try_number=1, map_index=-1)
[2025-12-29T20:45:14.311+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='scheduled__2025-12-28T00:00:00+00:00', try_number=1, map_index=-1)
[2025-12-29T20:45:14.319+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=mark_execution_start, run_id=manual__2025-12-29T19:43:36+00:00, map_index=-1, run_start_date=2025-12-29 19:44:15.258805+00:00, run_end_date=2025-12-29 19:44:15.479681+00:00, run_duration=0.220876, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=23, pool=default_pool, queue=default, priority_weight=11, operator=PythonOperator, queued_dttm=2025-12-29 19:44:11.285522+00:00, queued_by_job_id=17, pid=186584
[2025-12-29T20:45:14.320+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_culture, run_id=manual__2025-12-29T19:30:52+00:00, map_index=-1, run_start_date=2025-12-29 19:44:45.272058+00:00, run_end_date=2025-12-29 19:44:56.479843+00:00, run_duration=11.207785, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 19:44:11.285522+00:00, queued_by_job_id=17, pid=187029
[2025-12-29T20:45:14.321+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=check_accidents_schedule, run_id=manual__2025-12-29T19:32:36+00:00, map_index=-1, run_start_date=2025-12-29 19:44:22.234685+00:00, run_end_date=2025-12-29 19:44:22.438051+00:00, run_duration=0.203366, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=5, operator=ShortCircuitOperator, queued_dttm=2025-12-29 19:44:11.285522+00:00, queued_by_job_id=17, pid=186665
[2025-12-29T20:45:14.321+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=check_culture_schedule, run_id=manual__2025-12-29T19:32:36+00:00, map_index=-1, run_start_date=2025-12-29 19:44:19.070161+00:00, run_end_date=2025-12-29 19:44:19.243365+00:00, run_duration=0.173204, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=5, operator=ShortCircuitOperator, queued_dttm=2025-12-29 19:44:11.285522+00:00, queued_by_job_id=17, pid=186618
[2025-12-29T20:45:14.321+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=collect_prices, run_id=manual__2025-12-29T19:32:36+00:00, map_index=-1, run_start_date=2025-12-29 19:44:26.010903+00:00, run_end_date=2025-12-29 19:44:42.311328+00:00, run_duration=16.300425, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-12-29 19:44:11.285522+00:00, queued_by_job_id=17, pid=186693
[2025-12-29T20:45:14.322+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=create_exploitation_zone, run_id=scheduled__2025-12-28T00:00:00+00:00, map_index=-1, run_start_date=2025-12-29 19:44:59.933578+00:00, run_end_date=2025-12-29 19:45:13.833999+00:00, run_duration=13.900421, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=28, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-12-29 19:44:11.285522+00:00, queued_by_job_id=17, pid=187375
[2025-12-29T20:45:14.333+0100] {manager.py:293} ERROR - DagFileProcessorManager (PID=186537) last sent a heartbeat 63.14 seconds ago! Restarting it
[2025-12-29T20:45:14.335+0100] {process_utils.py:132} INFO - Sending 15 to group 186537. PIDs of all processes in the group: [186537]
[2025-12-29T20:45:14.335+0100] {process_utils.py:87} INFO - Sending the signal 15 to group 186537
[2025-12-29T20:45:14.469+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=186537, status='terminated', exitcode=0, started='20:44:10') (186537) terminated with exit code 0
[2025-12-29T20:45:14.475+0100] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 187712
[2025-12-29T20:45:14.480+0100] {settings.py:63} INFO - Configured default timezone UTC
[2025-12-29T20:45:14.500+0100] {job.py:229} INFO - Heartbeat recovered after 63.50 seconds
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:45:14.509+0100] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-12-29T20:45:14.719+0100] {scheduler_job_runner.py:423} INFO - 6 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:30:52+00:00 [scheduled]>
[2025-12-29T20:45:14.719+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:45:14.720+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 1/16 running and queued tasks
[2025-12-29T20:45:14.720+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 2/16 running and queued tasks
[2025-12-29T20:45:14.720+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 3/16 running and queued tasks
[2025-12-29T20:45:14.720+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 4/16 running and queued tasks
[2025-12-29T20:45:14.721+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 5/16 running and queued tasks
[2025-12-29T20:45:14.721+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:30:52+00:00 [scheduled]>
[2025-12-29T20:45:14.722+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:43:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:43:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:32:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:43:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:32:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:30:52+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:45:14.723+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_culture_schedule', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-12-29T20:45:14.723+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_culture_schedule', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:45:14.723+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_accidents_schedule', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-12-29T20:45:14.724+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_accidents_schedule', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:45:14.724+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_culture', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-12-29T20:45:14.724+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_culture', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:45:14.724+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_prices', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-12-29T20:45:14.724+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_prices', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:45:14.725+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T20:45:14.725+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:45:14.725+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='manual__2025-12-29T19:30:52+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-12-29T20:45:14.725+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'manual__2025-12-29T19:30:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:45:14.736+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_culture_schedule', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:45:16.235+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:45:16.652+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:45:16.780+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:45:16.782+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:45:16.809+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:45:16.886+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:45:16.887+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:45:16.914+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:43:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:45:17.765+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_accidents_schedule', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:45:19.726+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:45:20.165+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:45:20.329+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:45:20.331+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:45:20.374+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:45:20.451+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:45:20.452+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:45:20.489+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:43:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:45:21.450+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_culture', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:45:24.203+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:45:24.757+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:45:24.950+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:45:24.952+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:45:24.988+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:45:25.055+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:45:25.056+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:45:25.095+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:32:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:45:35.595+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_prices', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:45:38.363+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:45:38.910+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:45:39.117+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:45:39.120+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:45:39.178+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:45:39.274+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:45:39.276+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:45:39.321+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:43:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:45:58.149+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:46:00.626+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:46:01.152+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:46:01.332+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:46:01.335+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:46:01.380+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:46:01.447+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:46:01.448+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:46:01.491+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:32:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:46:28.367+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'manual__2025-12-29T19:30:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:46:30.894+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:46:31.527+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:46:31.756+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:46:31.759+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:46:31.828+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:46:31.924+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:46:31.925+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:46:31.979+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:30:52+00:00 [success]> on host frsia.localdomain
[2025-12-29T20:46:32.716+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_culture_schedule', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:46:32.717+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_accidents_schedule', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:46:32.718+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_culture', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:46:32.718+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_prices', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:46:32.719+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:46:32.719+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='manual__2025-12-29T19:30:52+00:00', try_number=1, map_index=-1)
[2025-12-29T20:46:32.728+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=check_accidents_schedule, run_id=manual__2025-12-29T19:43:36+00:00, map_index=-1, run_start_date=2025-12-29 19:45:20.548275+00:00, run_end_date=2025-12-29 19:45:20.811133+00:00, run_duration=0.262858, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=30, pool=default_pool, queue=default, priority_weight=5, operator=ShortCircuitOperator, queued_dttm=2025-12-29 19:45:14.721813+00:00, queued_by_job_id=17, pid=187771
[2025-12-29T20:46:32.729+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=check_culture_schedule, run_id=manual__2025-12-29T19:43:36+00:00, map_index=-1, run_start_date=2025-12-29 19:45:16.963328+00:00, run_end_date=2025-12-29 19:45:17.185165+00:00, run_duration=0.221837, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=29, pool=default_pool, queue=default, priority_weight=5, operator=ShortCircuitOperator, queued_dttm=2025-12-29 19:45:14.721813+00:00, queued_by_job_id=17, pid=187738
[2025-12-29T20:46:32.730+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=collect_prices, run_id=manual__2025-12-29T19:43:36+00:00, map_index=-1, run_start_date=2025-12-29 19:45:39.391089+00:00, run_end_date=2025-12-29 19:45:57.341712+00:00, run_duration=17.950623, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=32, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-12-29 19:45:14.721813+00:00, queued_by_job_id=17, pid=188105
[2025-12-29T20:46:32.731+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=create_exploitation_zone, run_id=manual__2025-12-29T19:30:52+00:00, map_index=-1, run_start_date=2025-12-29 19:46:06.149652+00:00, run_end_date=2025-12-29 19:46:06.149652+00:00, run_duration=0.0, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=None, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-12-29 19:45:14.721813+00:00, queued_by_job_id=17, pid=None
[2025-12-29T20:46:32.731+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=collect_culture, run_id=manual__2025-12-29T19:32:36+00:00, map_index=-1, run_start_date=2025-12-29 19:45:25.161035+00:00, run_end_date=2025-12-29 19:45:35.031087+00:00, run_duration=9.870052, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-12-29 19:45:14.721813+00:00, queued_by_job_id=17, pid=187825
[2025-12-29T20:46:32.732+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_prices, run_id=manual__2025-12-29T19:32:36+00:00, map_index=-1, run_start_date=2025-12-29 19:46:01.581849+00:00, run_end_date=2025-12-29 19:46:27.795047+00:00, run_duration=26.213198, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=33, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 19:45:14.721813+00:00, queued_by_job_id=17, pid=188446
[2025-12-29T20:46:32.744+0100] {manager.py:293} ERROR - DagFileProcessorManager (PID=187712) last sent a heartbeat 78.08 seconds ago! Restarting it
[2025-12-29T20:46:32.747+0100] {process_utils.py:132} INFO - Sending 15 to group 187712. PIDs of all processes in the group: [187712]
[2025-12-29T20:46:32.747+0100] {process_utils.py:87} INFO - Sending the signal 15 to group 187712
[2025-12-29T20:46:32.963+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=187712, status='terminated', exitcode=0, started='20:45:13') (187712) terminated with exit code 0
[2025-12-29T20:46:32.970+0100] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 188969
[2025-12-29T20:46:32.980+0100] {settings.py:63} INFO - Configured default timezone UTC
[2025-12-29T20:46:33.007+0100] {job.py:229} INFO - Heartbeat recovered after 78.52 seconds
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:46:33.033+0100] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-12-29T20:46:33.329+0100] {dagrun.py:854} INFO - Marking run <DagRun bcn_rental_prediction_pipeline @ 2025-12-29 19:30:52+00:00: manual__2025-12-29T19:30:52+00:00, state:running, queued_at: 2025-12-29 19:30:52.604549+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-12-29 19:30:53.847756+00:00 end:2025-12-29 19:46:33.331366+00:00
[2025-12-29T20:46:33.331+0100] {dagrun.py:905} INFO - DagRun Finished: dag_id=bcn_rental_prediction_pipeline, execution_date=2025-12-29 19:30:52+00:00, run_id=manual__2025-12-29T19:30:52+00:00, run_start_date=2025-12-29 19:30:53.847756+00:00, run_end_date=2025-12-29 19:46:33.331366+00:00, run_duration=939.48361, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-12-28 00:00:00+00:00, data_interval_end=2025-12-29 00:00:00+00:00, dag_hash=d14172f209e877fbcd41cb8a5b17e933
[2025-12-29T20:46:33.362+0100] {dagrun.py:823} ERROR - Marking run <DagRun bcn_rental_prediction_pipeline @ 2025-12-28 00:00:00+00:00: scheduled__2025-12-28T00:00:00+00:00, state:running, queued_at: 2025-12-29 19:30:47.389536+00:00. externally triggered: False> failed
Dag run  in failure state
Dag information:bcn_rental_prediction_pipeline Run id: scheduled__2025-12-28T00:00:00+00:00 external trigger: False
Failed with message: task_failure
[2025-12-29T20:46:33.363+0100] {dagrun.py:905} INFO - DagRun Finished: dag_id=bcn_rental_prediction_pipeline, execution_date=2025-12-28 00:00:00+00:00, run_id=scheduled__2025-12-28T00:00:00+00:00, run_start_date=2025-12-29 19:30:47.439094+00:00, run_end_date=2025-12-29 19:46:33.363815+00:00, run_duration=945.924721, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-12-28 00:00:00+00:00, data_interval_end=2025-12-29 00:00:00+00:00, dag_hash=d14172f209e877fbcd41cb8a5b17e933
[2025-12-29T20:46:33.374+0100] {dag.py:4180} INFO - Setting next_dagrun for bcn_rental_prediction_pipeline to 2025-12-29 00:00:00+00:00, run_after=2025-12-30 00:00:00+00:00
[2025-12-29T20:46:33.427+0100] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:43:36+00:00 [scheduled]>
[2025-12-29T20:46:33.428+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:46:33.429+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 1/16 running and queued tasks
[2025-12-29T20:46:33.429+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 2/16 running and queued tasks
[2025-12-29T20:46:33.430+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:43:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:32:36+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:43:36+00:00 [scheduled]>
[2025-12-29T20:46:33.435+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:43:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:32:36+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:43:36+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:46:33.436+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_culture', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-12-29T20:46:33.437+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_culture', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:46:33.437+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_culture', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T20:46:33.438+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_culture', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:46:33.438+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T20:46:33.439+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:46:33.458+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_culture', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:46:36.375+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:46:36.843+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:46:37.021+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:46:37.023+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:46:37.059+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:46:37.123+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:46:37.124+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:46:37.164+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:43:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:46:47.555+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_culture', 'manual__2025-12-29T19:32:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:46:50.051+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:46:50.569+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:46:50.780+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:46:50.783+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:46:50.828+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:46:50.891+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:46:50.893+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:46:50.934+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:32:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:47:11.943+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'manual__2025-12-29T19:43:36+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:47:14.253+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:47:14.683+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:47:14.842+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:47:14.845+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:47:14.876+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:47:14.966+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:47:14.968+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:47:15.002+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:43:36+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:47:26.579+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_culture', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:47:26.580+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_culture', run_id='manual__2025-12-29T19:32:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:47:26.580+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='manual__2025-12-29T19:43:36+00:00', try_number=1, map_index=-1)
[2025-12-29T20:47:26.590+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=collect_culture, run_id=manual__2025-12-29T19:43:36+00:00, map_index=-1, run_start_date=2025-12-29 19:46:37.238456+00:00, run_end_date=2025-12-29 19:46:46.906334+00:00, run_duration=9.667878, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=35, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-12-29 19:46:33.431763+00:00, queued_by_job_id=17, pid=189020
[2025-12-29T20:47:26.592+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_prices, run_id=manual__2025-12-29T19:43:36+00:00, map_index=-1, run_start_date=2025-12-29 19:47:15.061580+00:00, run_end_date=2025-12-29 19:47:26.000721+00:00, run_duration=10.939141, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 19:46:33.431763+00:00, queued_by_job_id=17, pid=189706
[2025-12-29T20:47:26.592+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_culture, run_id=manual__2025-12-29T19:32:36+00:00, map_index=-1, run_start_date=2025-12-29 19:46:51.006712+00:00, run_end_date=2025-12-29 19:47:11.180512+00:00, run_duration=20.1738, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=36, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 19:46:33.431763+00:00, queued_by_job_id=17, pid=189300
[2025-12-29T20:47:26.604+0100] {manager.py:293} ERROR - DagFileProcessorManager (PID=188969) last sent a heartbeat 53.33 seconds ago! Restarting it
[2025-12-29T20:47:26.607+0100] {process_utils.py:132} INFO - Sending 15 to group 188969. PIDs of all processes in the group: [188969]
[2025-12-29T20:47:26.607+0100] {process_utils.py:87} INFO - Sending the signal 15 to group 188969
[2025-12-29T20:47:26.782+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=188969, status='terminated', exitcode=0, started='20:46:32') (188969) terminated with exit code 0
[2025-12-29T20:47:26.788+0100] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 190010
[2025-12-29T20:47:26.796+0100] {settings.py:63} INFO - Configured default timezone UTC
[2025-12-29T20:47:26.816+0100] {job.py:229} INFO - Heartbeat recovered after 53.83 seconds
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:47:26.834+0100] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-12-29T20:47:26.833+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T20:48:33.429+0100] {dagrun.py:854} INFO - Marking run <DagRun bcn_rental_prediction_pipeline @ 2025-12-29 19:32:36+00:00: manual__2025-12-29T19:32:36+00:00, state:running, queued_at: 2025-12-29 19:32:36.724642+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-12-29 19:42:23.342585+00:00 end:2025-12-29 19:48:33.429551+00:00
[2025-12-29T20:48:33.429+0100] {dagrun.py:905} INFO - DagRun Finished: dag_id=bcn_rental_prediction_pipeline, execution_date=2025-12-29 19:32:36+00:00, run_id=manual__2025-12-29T19:32:36+00:00, run_start_date=2025-12-29 19:42:23.342585+00:00, run_end_date=2025-12-29 19:48:33.429551+00:00, run_duration=370.086966, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-12-28 00:00:00+00:00, data_interval_end=2025-12-29 00:00:00+00:00, dag_hash=d14172f209e877fbcd41cb8a5b17e933
[2025-12-29T20:48:33.432+0100] {dagrun.py:854} INFO - Marking run <DagRun bcn_rental_prediction_pipeline @ 2025-12-29 19:43:36+00:00: manual__2025-12-29T19:43:36+00:00, state:running, queued_at: 2025-12-29 19:43:36.612088+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-12-29 19:44:11.209744+00:00 end:2025-12-29 19:48:33.432471+00:00
[2025-12-29T20:48:33.432+0100] {dagrun.py:905} INFO - DagRun Finished: dag_id=bcn_rental_prediction_pipeline, execution_date=2025-12-29 19:43:36+00:00, run_id=manual__2025-12-29T19:43:36+00:00, run_start_date=2025-12-29 19:44:11.209744+00:00, run_end_date=2025-12-29 19:48:33.432471+00:00, run_duration=262.222727, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-12-28 00:00:00+00:00, data_interval_end=2025-12-29 00:00:00+00:00, dag_hash=d14172f209e877fbcd41cb8a5b17e933
Dag run  in running state
Dag information Queued at: 2025-12-29 19:49:46.254879+00:00 hash info: d14172f209e877fbcd41cb8a5b17e933
[2025-12-29T20:49:47.748+0100] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:49:47.749+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:49:47.749+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:49:47.750+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:49:47.751+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='mark_execution_start', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 11 and queue default
[2025-12-29T20:49:47.751+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'mark_execution_start', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:49:47.759+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'mark_execution_start', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:49:48.909+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:49:49.202+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:49:49.323+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:49:49.324+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:49:49.346+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:49:49.383+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:49:49.384+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:49:49.407+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.mark_execution_start manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:49:50.003+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='mark_execution_start', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T20:49:50.009+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=mark_execution_start, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 19:49:49.449662+00:00, run_end_date=2025-12-29 19:49:49.585635+00:00, run_duration=0.135973, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=11, operator=PythonOperator, queued_dttm=2025-12-29 19:49:47.749836+00:00, queued_by_job_id=17, pid=190727
[2025-12-29T20:49:50.162+0100] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:49:46+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:49:46+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:49:50.163+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:49:50.163+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 1/16 running and queued tasks
[2025-12-29T20:49:50.163+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 2/16 running and queued tasks
[2025-12-29T20:49:50.164+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:49:46+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:49:46+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:49:50.165+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:49:46+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:49:46+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:49:50.165+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_culture_schedule', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-12-29T20:49:50.165+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_culture_schedule', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:49:50.166+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_accidents_schedule', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-12-29T20:49:50.166+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_accidents_schedule', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:49:50.166+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_prices', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-12-29T20:49:50.166+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_prices', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:49:50.177+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_culture_schedule', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:49:51.756+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:49:52.168+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:49:52.315+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:49:52.317+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:49:52.348+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:49:52.406+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:49:52.407+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:49:52.437+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.check_culture_schedule manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:49:53.232+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_accidents_schedule', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:49:55.331+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:49:55.790+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:49:55.946+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:49:55.948+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:49:55.976+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:49:56.045+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:49:56.046+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:49:56.086+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:49:56.974+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_prices', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:49:58.913+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:49:59.401+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:49:59.559+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:49:59.561+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:49:59.600+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:49:59.667+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:49:59.668+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:49:59.707+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.collect_prices manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:50:20.520+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_culture_schedule', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T20:50:20.523+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_accidents_schedule', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T20:50:20.524+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_prices', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T20:50:20.544+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=check_accidents_schedule, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 19:49:56.152070+00:00, run_end_date=2025-12-29 19:49:56.424174+00:00, run_duration=0.272104, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=40, pool=default_pool, queue=default, priority_weight=5, operator=ShortCircuitOperator, queued_dttm=2025-12-29 19:49:50.164493+00:00, queued_by_job_id=17, pid=190801
[2025-12-29T20:50:20.548+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=check_culture_schedule, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 19:49:52.491688+00:00, run_end_date=2025-12-29 19:49:52.698672+00:00, run_duration=0.206984, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=5, operator=ShortCircuitOperator, queued_dttm=2025-12-29 19:49:50.164493+00:00, queued_by_job_id=17, pid=190764
[2025-12-29T20:50:20.551+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=collect_prices, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 19:49:59.772053+00:00, run_end_date=2025-12-29 19:50:18.947265+00:00, run_duration=19.175212, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=41, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-12-29 19:49:50.164493+00:00, queued_by_job_id=17, pid=190834
[2025-12-29T20:50:20.597+0100] {job.py:229} INFO - Heartbeat recovered after 34.01 seconds
[2025-12-29T20:50:21.230+0100] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:49:46+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:50:21.232+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:50:21.233+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 1/16 running and queued tasks
[2025-12-29T20:50:21.234+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:49:46+00:00 [scheduled]>
	<TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:50:21.239+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:49:46+00:00 [scheduled]>, <TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:50:21.241+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_culture', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-12-29T20:50:21.242+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_culture', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:50:21.243+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T20:50:21.244+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:50:21.268+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_culture', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:50:27.377+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:50:27.954+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:50:28.152+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:50:28.155+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:50:28.203+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:50:28.296+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:50:28.297+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:50:28.341+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.collect_culture manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:50:43.272+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_prices', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:50:47.757+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:50:48.356+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:50:48.544+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:50:48.547+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:50:48.586+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:50:48.652+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:50:48.653+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:50:48.695+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_prices manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:51:13.169+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_culture', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T20:51:13.169+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_prices', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T20:51:13.177+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=collect_culture, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 19:50:28.416477+00:00, run_end_date=2025-12-29 19:50:42.186457+00:00, run_duration=13.76998, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=42, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-12-29 19:50:21.236076+00:00, queued_by_job_id=17, pid=191265
[2025-12-29T20:51:13.178+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_prices, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 19:50:48.763827+00:00, run_end_date=2025-12-29 19:51:12.436946+00:00, run_duration=23.673119, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=43, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 19:50:21.236076+00:00, queued_by_job_id=17, pid=191569
[2025-12-29T20:51:13.190+0100] {manager.py:293} ERROR - DagFileProcessorManager (PID=190010) last sent a heartbeat 52.07 seconds ago! Restarting it
[2025-12-29T20:51:13.193+0100] {process_utils.py:132} INFO - Sending 15 to group 190010. PIDs of all processes in the group: [190010]
[2025-12-29T20:51:13.194+0100] {process_utils.py:87} INFO - Sending the signal 15 to group 190010
[2025-12-29T20:51:13.408+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=190010, status='terminated', exitcode=0, started='20:47:25') (190010) terminated with exit code 0
[2025-12-29T20:51:13.415+0100] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 191994
[2025-12-29T20:51:13.423+0100] {settings.py:63} INFO - Configured default timezone UTC
[2025-12-29T20:51:13.446+0100] {job.py:229} INFO - Heartbeat recovered after 52.87 seconds
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:51:13.473+0100] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-12-29T20:51:13.949+0100] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:51:13.952+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:51:13.953+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:51:13.956+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:51:13.957+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_culture', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T20:51:13.958+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_culture', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:51:13.973+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_culture', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:51:16.558+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:51:17.132+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:51:17.354+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:51:17.356+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:51:17.394+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:51:17.469+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:51:17.470+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:51:17.510+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_culture manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:51:44.782+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_culture', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T20:51:44.788+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_culture, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 19:51:17.577739+00:00, run_end_date=2025-12-29 19:51:43.925421+00:00, run_duration=26.347682, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=44, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 19:51:13.954152+00:00, queued_by_job_id=17, pid=192031
[2025-12-29T20:51:44.823+0100] {job.py:229} INFO - Heartbeat recovered after 31.39 seconds
[2025-12-29T20:51:45.015+0100] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:51:45.016+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:51:45.016+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:51:45.019+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:51:45.019+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-12-29T20:51:45.020+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:51:45.035+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:51:48.551+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:51:50.046+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:51:50.554+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:51:50.561+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:51:50.723+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:51:50.951+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:51:50.954+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:51:51.108+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:52:09.527+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T20:52:09.532+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=create_exploitation_zone, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 19:51:51.375164+00:00, run_end_date=2025-12-29 19:52:08.846502+00:00, run_duration=17.471338, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=45, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-12-29 19:51:45.017647+00:00, queued_by_job_id=17, pid=192473
[2025-12-29T20:52:26.991+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T20:57:08.947+0100] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:57:08.948+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T20:57:08.948+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T20:57:08.949+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T20:57:08.949+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='manual__2025-12-29T19:49:46+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-12-29T20:57:08.949+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T20:57:08.958+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T20:57:10.173+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T20:57:10.432+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T20:57:10.540+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:57:10.542+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:57:10.565+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T20:57:10.606+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T20:57:10.607+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T20:57:10.637+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T20:57:29.133+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='manual__2025-12-29T19:49:46+00:00', try_number=2, map_index=-1)
[2025-12-29T20:57:29.140+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=create_exploitation_zone, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 19:57:10.692091+00:00, run_end_date=2025-12-29 19:57:28.443202+00:00, run_duration=17.751111, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=46, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-12-29 19:57:08.948652+00:00, queued_by_job_id=17, pid=195168
[2025-12-29T20:57:29.196+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T20:57:29.479+0100] {dagrun.py:823} ERROR - Marking run <DagRun bcn_rental_prediction_pipeline @ 2025-12-29 19:49:46+00:00: manual__2025-12-29T19:49:46+00:00, state:running, queued_at: 2025-12-29 19:49:46.254879+00:00. externally triggered: True> failed
Dag run  in failure state
Dag information:bcn_rental_prediction_pipeline Run id: manual__2025-12-29T19:49:46+00:00 external trigger: True
Failed with message: task_failure
[2025-12-29T20:57:29.480+0100] {dagrun.py:905} INFO - DagRun Finished: dag_id=bcn_rental_prediction_pipeline, execution_date=2025-12-29 19:49:46+00:00, run_id=manual__2025-12-29T19:49:46+00:00, run_start_date=2025-12-29 19:49:47.717315+00:00, run_end_date=2025-12-29 19:57:29.479889+00:00, run_duration=461.762574, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-12-28 00:00:00+00:00, data_interval_end=2025-12-29 00:00:00+00:00, dag_hash=7fc5f0c1684670f955e4c2d758007b27
Dag run  in running state
Dag information Queued at: 2025-12-29 20:00:51.311287+00:00 hash info: 7fc5f0c1684670f955e4c2d758007b27
[2025-12-29T21:00:51.943+0100] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:00:51.944+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T21:00:51.944+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:00:51.945+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T21:00:51.945+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_accidents_schedule', run_id='manual__2025-12-29T19:49:46+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-12-29T21:00:51.946+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_accidents_schedule', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T21:00:51.954+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'check_accidents_schedule', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T21:00:53.206+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T21:00:53.613+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T21:00:53.733+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:00:53.734+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:00:53.763+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:00:53.814+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T21:00:53.815+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:00:53.844+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.check_accidents_schedule manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T21:00:54.682+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='check_accidents_schedule', run_id='manual__2025-12-29T19:49:46+00:00', try_number=2, map_index=-1)
[2025-12-29T21:00:54.687+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=check_accidents_schedule, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 20:00:53.897542+00:00, run_end_date=2025-12-29 20:00:54.111801+00:00, run_duration=0.214259, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=2, job_id=47, pool=default_pool, queue=default, priority_weight=5, operator=ShortCircuitOperator, queued_dttm=2025-12-29 20:00:51.944786+00:00, queued_by_job_id=17, pid=196448
[2025-12-29T21:00:55.154+0100] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.collect_accidents manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:00:55.154+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T21:00:55.155+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.collect_accidents manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:00:55.156+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.collect_accidents manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T21:00:55.157+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_accidents', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-12-29T21:00:55.157+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_accidents', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T21:00:55.170+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'collect_accidents', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T21:00:57.136+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T21:00:57.674+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T21:00:57.824+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:00:57.826+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:00:57.857+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:00:57.917+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T21:00:57.918+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:00:57.951+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.collect_accidents manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T21:01:06.384+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='collect_accidents', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T21:01:06.390+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=collect_accidents, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 20:00:58.028429+00:00, run_end_date=2025-12-29 20:01:05.828550+00:00, run_duration=7.800121, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=48, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-12-29 20:00:55.155705+00:00, queued_by_job_id=17, pid=196489
[2025-12-29T21:01:06.647+0100] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.format_accidents manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:01:06.648+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T21:01:06.648+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.format_accidents manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:01:06.650+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.format_accidents manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T21:01:06.651+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_accidents', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-12-29T21:01:06.651+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_accidents', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T21:01:06.666+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'format_accidents', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T21:01:08.811+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T21:01:09.387+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T21:01:09.582+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:01:09.584+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:01:09.619+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:01:09.693+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T21:01:09.694+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:01:09.736+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.format_accidents manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T21:02:04.738+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='format_accidents', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T21:02:04.744+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=format_accidents, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 20:01:09.804289+00:00, run_end_date=2025-12-29 20:02:04.231710+00:00, run_duration=54.427421, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=49, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-12-29 20:01:06.649343+00:00, queued_by_job_id=17, pid=196727
[2025-12-29T21:02:04.756+0100] {manager.py:293} ERROR - DagFileProcessorManager (PID=191994) last sent a heartbeat 58.17 seconds ago! Restarting it
[2025-12-29T21:02:04.757+0100] {process_utils.py:132} INFO - Sending 15 to group 191994. PIDs of all processes in the group: [191994]
[2025-12-29T21:02:04.758+0100] {process_utils.py:87} INFO - Sending the signal 15 to group 191994
[2025-12-29T21:02:04.892+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=191994, status='terminated', exitcode=0, started='20:51:12') (191994) terminated with exit code 0
[2025-12-29T21:02:04.897+0100] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 197445
[2025-12-29T21:02:04.905+0100] {settings.py:63} INFO - Configured default timezone UTC
[2025-12-29T21:02:04.923+0100] {job.py:229} INFO - Heartbeat recovered after 58.52 seconds
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T21:02:04.938+0100] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-12-29T21:02:05.243+0100] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:02:05.243+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T21:02:05.243+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:02:05.245+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T21:02:05.245+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='manual__2025-12-29T19:49:46+00:00', try_number=3, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-12-29T21:02:05.246+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T21:02:05.257+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'create_exploitation_zone', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T21:02:07.181+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T21:02:07.831+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T21:02:08.040+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:02:08.042+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:02:08.085+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:02:08.142+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T21:02:08.143+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:02:08.181+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.create_exploitation_zone manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T21:02:51.059+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='create_exploitation_zone', run_id='manual__2025-12-29T19:49:46+00:00', try_number=3, map_index=-1)
[2025-12-29T21:02:51.065+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=create_exploitation_zone, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 20:02:08.254628+00:00, run_end_date=2025-12-29 20:02:50.523330+00:00, run_duration=42.268702, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=3, max_tries=3, job_id=50, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-12-29 20:02:05.244440+00:00, queued_by_job_id=17, pid=197473
[2025-12-29T21:02:51.096+0100] {job.py:229} INFO - Heartbeat recovered after 46.19 seconds
[2025-12-29T21:02:51.105+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:02:51.262+0100] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: bcn_rental_prediction_pipeline.train_and_evaluate_model manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:02:51.263+0100] {scheduler_job_runner.py:495} INFO - DAG bcn_rental_prediction_pipeline has 0/16 running and queued tasks
[2025-12-29T21:02:51.263+0100] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: bcn_rental_prediction_pipeline.train_and_evaluate_model manual__2025-12-29T19:49:46+00:00 [scheduled]>
[2025-12-29T21:02:51.264+0100] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: bcn_rental_prediction_pipeline.train_and_evaluate_model manual__2025-12-29T19:49:46+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-12-29T21:02:51.264+0100] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='train_and_evaluate_model', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-12-29T21:02:51.265+0100] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'train_and_evaluate_model', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
[2025-12-29T21:02:51.277+0100] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'bcn_rental_prediction_pipeline', 'train_and_evaluate_model', 'manual__2025-12-29T19:49:46+00:00', '--local', '--subdir', 'DAGS_FOLDER/orchestration.py']
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T21:02:52.826+0100] {dagbag.py:588} INFO - Filling up the DagBag from /home/onasi/proj2_BDA/airflow_home/dags/orchestration.py
[2025-12-29T21:02:53.387+0100] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-12-29T21:02:53.574+0100] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:02:53.576+0100] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:02:53.606+0100] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-12-29T21:02:53.656+0100] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-12-29T21:02:53.657+0100] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-12-29T21:02:53.690+0100] {task_command.py:467} INFO - Running <TaskInstance: bcn_rental_prediction_pipeline.train_and_evaluate_model manual__2025-12-29T19:49:46+00:00 [queued]> on host frsia.localdomain
[2025-12-29T21:06:03.402+0100] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='bcn_rental_prediction_pipeline', task_id='train_and_evaluate_model', run_id='manual__2025-12-29T19:49:46+00:00', try_number=1, map_index=-1)
[2025-12-29T21:06:03.416+0100] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=bcn_rental_prediction_pipeline, task_id=train_and_evaluate_model, run_id=manual__2025-12-29T19:49:46+00:00, map_index=-1, run_start_date=2025-12-29 20:02:53.750174+00:00, run_end_date=2025-12-29 20:06:02.363908+00:00, run_duration=188.613734, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=51, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-12-29 20:02:51.263737+00:00, queued_by_job_id=17, pid=198093
[2025-12-29T21:06:03.428+0100] {manager.py:293} ERROR - DagFileProcessorManager (PID=197445) last sent a heartbeat 192.20 seconds ago! Restarting it
[2025-12-29T21:06:03.431+0100] {process_utils.py:132} INFO - Sending 15 to group 197445. PIDs of all processes in the group: [197445]
[2025-12-29T21:06:03.432+0100] {process_utils.py:87} INFO - Sending the signal 15 to group 197445
[2025-12-29T21:06:03.687+0100] {process_utils.py:80} INFO - Process psutil.Process(pid=197445, status='terminated', exitcode=0, started='21:02:04') (197445) terminated with exit code 0
[2025-12-29T21:06:03.696+0100] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 200025
[2025-12-29T21:06:03.709+0100] {settings.py:63} INFO - Configured default timezone UTC
[2025-12-29T21:06:03.738+0100] {job.py:229} INFO - Heartbeat recovered after 192.65 seconds
/home/onasi/proj2_BDA/.venv/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
[2025-12-29T21:06:03.774+0100] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-12-29T21:06:04.315+0100] {dagrun.py:854} INFO - Marking run <DagRun bcn_rental_prediction_pipeline @ 2025-12-29 19:49:46+00:00: manual__2025-12-29T19:49:46+00:00, state:running, queued_at: 2025-12-29 20:00:51.311287+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-12-29 20:00:51.912436+00:00 end:2025-12-29 20:06:04.315999+00:00
[2025-12-29T21:06:04.316+0100] {dagrun.py:905} INFO - DagRun Finished: dag_id=bcn_rental_prediction_pipeline, execution_date=2025-12-29 19:49:46+00:00, run_id=manual__2025-12-29T19:49:46+00:00, run_start_date=2025-12-29 20:00:51.912436+00:00, run_end_date=2025-12-29 20:06:04.315999+00:00, run_duration=312.403563, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-12-28 00:00:00+00:00, data_interval_end=2025-12-29 00:00:00+00:00, dag_hash=7fc5f0c1684670f955e4c2d758007b27
[2025-12-29T21:07:51.241+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:12:51.387+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:19:46.206+0100] {job.py:229} INFO - Heartbeat recovered after 297.37 seconds
[2025-12-29T21:22:47.575+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:27:47.690+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:32:47.810+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:37:47.950+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:42:48.084+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:47:48.232+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:52:48.369+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T21:57:48.516+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T22:02:48.771+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:01:06.050+0100] {job.py:229} INFO - Heartbeat recovered after 3238.86 seconds
[2025-12-29T23:01:06.738+0100] {job.py:229} INFO - Heartbeat recovered after 2427.00 seconds
[2025-12-29T23:01:43.176+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:06:43.416+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:11:43.555+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:16:43.696+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:21:43.833+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:26:43.967+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:31:44.103+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:36:44.236+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:41:44.376+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:46:44.387+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:51:44.527+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-29T23:56:44.664+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:01:44.801+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:06:44.847+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:11:44.986+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:16:45.122+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:21:45.268+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:26:45.406+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:31:45.471+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:36:45.602+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:41:45.738+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T00:46:45.787+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T05:39:48.460+0100] {job.py:229} INFO - Heartbeat recovered after 17352.91 seconds
[2025-12-30T05:50:55.292+0100] {job.py:229} INFO - Heartbeat recovered after 666.84 seconds
[2025-12-30T08:47:39.411+0100] {job.py:229} INFO - Heartbeat recovered after 10604.49 seconds
[2025-12-30T08:48:41.808+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T08:56:11.306+0100] {job.py:229} INFO - Heartbeat recovered after 184.68 seconds
[2025-12-30T08:56:45.057+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:01:45.251+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:06:45.400+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:11:45.550+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:16:45.691+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:21:45.837+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:26:45.963+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:31:46.123+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:36:46.475+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:41:46.623+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:46:46.766+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:51:46.916+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T09:56:47.083+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T10:01:47.224+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T10:06:47.378+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T10:12:05.670+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T11:42:45.147+0100] {job.py:229} INFO - Heartbeat recovered after 5160.81 seconds
[2025-12-30T11:43:03.205+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T11:48:03.346+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T11:53:03.595+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T11:58:03.739+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:03:03.786+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:08:03.899+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:13:12.862+0100] {job.py:229} INFO - Heartbeat recovered after 276.87 seconds
[2025-12-30T12:17:37.330+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:22:37.478+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:27:37.621+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:32:37.869+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:37:38.017+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:40:31.382+0100] {job.py:229} INFO - Heartbeat recovered after 147.34 seconds
[2025-12-30T12:45:01.001+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:50:01.151+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T12:55:01.305+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T13:08:32.673+0100] {job.py:229} INFO - Heartbeat recovered after 570.59 seconds
[2025-12-30T13:09:27.968+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T13:14:28.122+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T13:19:28.274+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T13:55:30.171+0100] {job.py:229} INFO - Heartbeat recovered after 2083.47 seconds
[2025-12-30T13:55:30.975+0100] {manager.py:537} INFO - DAG tutorial_objectstorage is missing and will be deactivated.
[2025-12-30T13:55:30.987+0100] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-12-30T13:55:31.000+0100] {manager.py:553} INFO - Deleted DAG tutorial_objectstorage in serialized_dag table
[2025-12-30T16:53:32.986+0100] {job.py:229} INFO - Heartbeat recovered after 10682.83 seconds
[2025-12-30T19:03:33.546+0100] {job.py:229} INFO - Heartbeat recovered after 7800.57 seconds
[2025-12-30T19:07:04.355+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T19:12:07.898+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T19:36:44.449+0100] {job.py:229} INFO - Heartbeat recovered after 1217.24 seconds
[2025-12-30T20:11:48.994+0100] {job.py:229} INFO - Heartbeat recovered after 2104.55 seconds
[2025-12-30T20:12:22.625+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T20:17:27.301+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T20:22:32.300+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T20:27:37.695+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T20:32:44.069+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T20:37:49.822+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T20:42:55.776+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T20:48:02.121+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T20:53:08.102+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T20:58:13.880+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:03:20.193+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:08:25.934+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:13:31.443+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:18:38.312+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:23:44.559+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:28:50.740+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:33:57.221+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:39:03.378+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:44:09.233+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T21:49:14.947+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T22:03:36.694+0100] {job.py:229} INFO - Heartbeat recovered after 829.79 seconds
[2025-12-30T22:03:37.710+0100] {manager.py:537} INFO - DAG example_dynamic_task_mapping is missing and will be deactivated.
[2025-12-30T22:03:37.713+0100] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-12-30T22:03:37.724+0100] {manager.py:553} INFO - Deleted DAG example_dynamic_task_mapping in serialized_dag table
[2025-12-30T22:17:01.013+0100] {job.py:229} INFO - Heartbeat recovered after 804.34 seconds
[2025-12-30T22:21:31.209+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T22:26:42.344+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-12-30T22:31:55.330+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:03:58.927+0100] {job.py:229} INFO - Heartbeat recovered after 134915.77 seconds
[2026-01-01T12:05:38.220+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:11:25.706+0100] {job.py:229} INFO - Heartbeat recovered after 247.88 seconds
[2026-01-01T12:14:37.948+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:19:33.025+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:24:28.016+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:29:22.349+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:34:15.817+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:39:09.858+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:44:03.743+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:48:56.758+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:53:50.035+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T12:58:43.628+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:03:37.103+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:08:30.564+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:13:23.221+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:18:28.124+0100] {job.py:229} INFO - Heartbeat recovered after 39.41 seconds
[2026-01-01T13:18:51.950+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:23:47.607+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:28:43.775+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:33:37.943+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:38:32.427+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:43:26.792+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T13:48:20.292+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T14:03:44.126+0100] {job.py:229} INFO - Heartbeat recovered after 653.72 seconds
[2026-01-01T14:03:44.294+0100] {manager.py:537} INFO - DAG example_params_trigger_ui is missing and will be deactivated.
[2026-01-01T14:03:44.296+0100] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2026-01-01T14:03:44.343+0100] {manager.py:553} INFO - Deleted DAG example_params_trigger_ui in serialized_dag table
[2026-01-01T14:04:04.106+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T14:08:57.756+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T14:13:51.153+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-01T14:18:44.369+0100] {scheduler_job_runner.py:1852} INFO - Adopting or resetting orphaned tasks for active dag runs
